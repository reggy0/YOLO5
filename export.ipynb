{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "export.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMlc7FZlOlfENVgsex5+wB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reggy0/YOLO5/blob/main/export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rUqNgvJ77lf"
      },
      "outputs": [],
      "source": [
        "\"\"\"Exports a YOLOv5 *.pt model to ONNX and TorchScript formats\n",
        "\n",
        "Usage:\n",
        "    $ export PYTHONPATH=\"$PWD\" && python models/export.py --weights ./weights/yolov5s.pt --img 640 --batch 1\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "\n",
        "from models.common import *\n",
        "from utils import google_utils\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--weights', type=str, default='./yolov5s.pt', help='weights path')\n",
        "    parser.add_argument('--img-size', nargs='+', type=int, default=[640, 640], help='image size')\n",
        "    parser.add_argument('--batch-size', type=int, default=1, help='batch size')\n",
        "    opt = parser.parse_args()\n",
        "    opt.img_size *= 2 if len(opt.img_size) == 1 else 1  # expand\n",
        "    print(opt)\n",
        "\n",
        "    # Input\n",
        "    img = torch.zeros((opt.batch_size, 3, *opt.img_size))  # image size(1,3,320,192) iDetection\n",
        "\n",
        "    # Load PyTorch model\n",
        "    google_utils.attempt_download(opt.weights)\n",
        "    model = torch.load(opt.weights, map_location=torch.device('cpu'))['model'].float()\n",
        "    model.eval()\n",
        "    model.model[-1].export = True  # set Detect() layer export=True\n",
        "    y = model(img)  # dry run\n",
        "\n",
        "    # TorchScript export\n",
        "    try:\n",
        "        print('\\nStarting TorchScript export with torch %s...' % torch.__version__)\n",
        "        f = opt.weights.replace('.pt', '.torchscript')  # filename\n",
        "        ts = torch.jit.trace(model, img)\n",
        "        ts.save(f)\n",
        "        print('TorchScript export success, saved as %s' % f)\n",
        "    except Exception as e:\n",
        "        print('TorchScript export failure: %s' % e)\n",
        "\n",
        "    # ONNX export\n",
        "    try:\n",
        "        import onnx\n",
        "\n",
        "        print('\\nStarting ONNX export with onnx %s...' % onnx.__version__)\n",
        "        f = opt.weights.replace('.pt', '.onnx')  # filename\n",
        "        model.fuse()  # only for ONNX\n",
        "        torch.onnx.export(model, img, f, verbose=False, opset_version=12, input_names=['images'],\n",
        "                          output_names=['classes', 'boxes'] if y is None else ['output'])\n",
        "\n",
        "        # Checks\n",
        "        onnx_model = onnx.load(f)  # load onnx model\n",
        "        onnx.checker.check_model(onnx_model)  # check onnx model\n",
        "        print(onnx.helper.printable_graph(onnx_model.graph))  # print a human readable model\n",
        "        print('ONNX export success, saved as %s' % f)\n",
        "    except Exception as e:\n",
        "        print('ONNX export failure: %s' % e)\n",
        "\n",
        "    # CoreML export\n",
        "    try:\n",
        "        import coremltools as ct\n",
        "\n",
        "        print('\\nStarting CoreML export with coremltools %s...' % ct.__version__)\n",
        "        model = ct.convert(ts, inputs=[ct.ImageType(name='images', shape=img.shape)])  # convert\n",
        "        f = opt.weights.replace('.pt', '.mlmodel')  # filename\n",
        "        model.save(f)\n",
        "        print('CoreML export success, saved as %s' % f)\n",
        "    except Exception as e:\n",
        "        print('CoreML export failure: %s' % e)\n",
        "\n",
        "    # Finish\n",
        "    print('\\nExport complete. Visualize with https://github.com/lutzroeder/netron.')"
      ]
    }
  ]
}