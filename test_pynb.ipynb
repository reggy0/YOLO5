{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.pynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOdF35pcSZqy1vnEPJ98sds",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reggy0/YOLO5/blob/main/test_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d3GVhIHBVtr"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "\n",
        "from utils import google_utils\n",
        "from utils.datasets import *\n",
        "from utils.utils import *\n",
        "\n",
        "\n",
        "def test(data,\n",
        "         weights=None,\n",
        "         batch_size=16,\n",
        "         imgsz=640,\n",
        "         conf_thres=0.001,\n",
        "         iou_thres=0.6,  # for NMS\n",
        "         save_json=False,\n",
        "         single_cls=False,\n",
        "         augment=False,\n",
        "         verbose=False,\n",
        "         model=None,\n",
        "         dataloader=None,\n",
        "         merge=False):\n",
        "    # Initialize/load model and set device\n",
        "    if model is None:\n",
        "        training = False\n",
        "        device = torch_utils.select_device(opt.device, batch_size=batch_size)\n",
        "\n",
        "        # Remove previous\n",
        "        for f in glob.glob('test_batch*.jpg'):\n",
        "            os.remove(f)\n",
        "\n",
        "        # Load model\n",
        "        google_utils.attempt_download(weights)\n",
        "        model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
        "        torch_utils.model_info(model)\n",
        "        model.fuse()\n",
        "        model.to(device)\n",
        "        imgsz = check_img_size(imgsz, s=model.model[-1].stride.max())  # check img_size\n",
        "\n",
        "        # Multi-GPU disabled, incompatible with .half() https://github.com/ultralytics/yolov5/issues/99\n",
        "        # if device.type != 'cpu' and torch.cuda.device_count() > 1:\n",
        "        #     model = nn.DataParallel(model)\n",
        "\n",
        "    else:  # called by train.py\n",
        "        training = True\n",
        "        device = next(model.parameters()).device  # get model device\n",
        "\n",
        "    # Half\n",
        "    half = device.type != 'cpu' and torch.cuda.device_count() == 1  # half precision only supported on single-GPU\n",
        "    if half:\n",
        "        model.half()  # to FP16\n",
        "\n",
        "    # Configure\n",
        "    model.eval()\n",
        "    with open(data) as f:\n",
        "        data = yaml.load(f, Loader=yaml.FullLoader)  # model dict\n",
        "    nc = 1 if single_cls else int(data['nc'])  # number of classes\n",
        "    iouv = torch.linspace(0.5, 0.95, 10).to(device)  # iou vector for mAP@0.5:0.95\n",
        "    niou = iouv.numel()\n",
        "\n",
        "    # Dataloader\n",
        "    if dataloader is None:  # not training\n",
        "        merge = opt.merge  # use Merge NMS\n",
        "        img = torch.zeros((1, 3, imgsz, imgsz), device=device)  # init img\n",
        "        _ = model(img.half() if half else img) if device.type != 'cpu' else None  # run once\n",
        "        path = data['test'] if opt.task == 'test' else data['val']  # path to val/test images\n",
        "        dataloader = create_dataloader(path, imgsz, batch_size, int(max(model.stride)), opt,\n",
        "                                       hyp=None, augment=False, cache=False, pad=0.5, rect=True)[0]\n",
        "\n",
        "    seen = 0\n",
        "    names = model.names if hasattr(model, 'names') else model.module.names\n",
        "    coco91class = coco80_to_coco91_class()\n",
        "    s = ('%20s' + '%12s' * 6) % ('Class', 'Images', 'Targets', 'P', 'R', 'mAP@.5', 'mAP@.5:.95')\n",
        "    p, r, f1, mp, mr, map50, map, t0, t1 = 0., 0., 0., 0., 0., 0., 0., 0., 0.\n",
        "    loss = torch.zeros(3, device=device)\n",
        "    jdict, stats, ap, ap_class = [], [], [], []\n",
        "    for batch_i, (img, targets, paths, shapes) in enumerate(tqdm(dataloader, desc=s)):\n",
        "        img = img.to(device)\n",
        "        img = img.half() if half else img.float()  # uint8 to fp16/32\n",
        "        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
        "        targets = targets.to(device)\n",
        "        nb, _, height, width = img.shape  # batch size, channels, height, width\n",
        "        whwh = torch.Tensor([width, height, width, height]).to(device)\n",
        "\n",
        "        # Disable gradients\n",
        "        with torch.no_grad():\n",
        "            # Run model\n",
        "            t = torch_utils.time_synchronized()\n",
        "            inf_out, train_out = model(img, augment=augment)  # inference and training outputs\n",
        "            t0 += torch_utils.time_synchronized() - t\n",
        "\n",
        "            # Compute loss\n",
        "            if training:  # if model has loss hyperparameters\n",
        "                loss += compute_loss([x.float() for x in train_out], targets, model)[1][:3]  # GIoU, obj, cls\n",
        "\n",
        "            # Run NMS\n",
        "            t = torch_utils.time_synchronized()\n",
        "            output = non_max_suppression(inf_out, conf_thres=conf_thres, iou_thres=iou_thres, merge=merge)\n",
        "            t1 += torch_utils.time_synchronized() - t\n",
        "\n",
        "        # Statistics per image\n",
        "        for si, pred in enumerate(output):\n",
        "            labels = targets[targets[:, 0] == si, 1:]\n",
        "            nl = len(labels)\n",
        "            tcls = labels[:, 0].tolist() if nl else []  # target class\n",
        "            seen += 1\n",
        "\n",
        "            if pred is None:\n",
        "                if nl:\n",
        "                    stats.append((torch.zeros(0, niou, dtype=torch.bool), torch.Tensor(), torch.Tensor(), tcls))\n",
        "                continue\n",
        "\n",
        "            # Append to text file\n",
        "            # with open('test.txt', 'a') as file:\n",
        "            #    [file.write('%11.5g' * 7 % tuple(x) + '\\n') for x in pred]\n",
        "\n",
        "            # Clip boxes to image bounds\n",
        "            clip_coords(pred, (height, width))\n",
        "\n",
        "            # Append to pycocotools JSON dictionary\n",
        "            if save_json:\n",
        "                # [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...\n",
        "                image_id = int(Path(paths[si]).stem.split('_')[-1])\n",
        "                box = pred[:, :4].clone()  # xyxy\n",
        "                scale_coords(img[si].shape[1:], box, shapes[si][0], shapes[si][1])  # to original shape\n",
        "                box = xyxy2xywh(box)  # xywh\n",
        "                box[:, :2] -= box[:, 2:] / 2  # xy center to top-left corner\n",
        "                for p, b in zip(pred.tolist(), box.tolist()):\n",
        "                    jdict.append({'image_id': image_id,\n",
        "                                  'category_id': coco91class[int(p[5])],\n",
        "                                  'bbox': [round(x, 3) for x in b],\n",
        "                                  'score': round(p[4], 5)})\n",
        "\n",
        "            # Assign all predictions as incorrect\n",
        "            correct = torch.zeros(pred.shape[0], niou, dtype=torch.bool, device=device)\n",
        "            if nl:\n",
        "                detected = []  # target indices\n",
        "                tcls_tensor = labels[:, 0]\n",
        "\n",
        "                # target boxes\n",
        "                tbox = xywh2xyxy(labels[:, 1:5]) * whwh\n",
        "\n",
        "                # Per target class\n",
        "                for cls in torch.unique(tcls_tensor):\n",
        "                    ti = (cls == tcls_tensor).nonzero().view(-1)  # prediction indices\n",
        "                    pi = (cls == pred[:, 5]).nonzero().view(-1)  # target indices\n",
        "\n",
        "                    # Search for detections\n",
        "                    if pi.shape[0]:\n",
        "                        # Prediction to target ious\n",
        "                        ious, i = box_iou(pred[pi, :4], tbox[ti]).max(1)  # best ious, indices\n",
        "\n",
        "                        # Append detections\n",
        "                        for j in (ious > iouv[0]).nonzero():\n",
        "                            d = ti[i[j]]  # detected target\n",
        "                            if d not in detected:\n",
        "                                detected.append(d)\n",
        "                                correct[pi[j]] = ious[j] > iouv  # iou_thres is 1xn\n",
        "                                if len(detected) == nl:  # all targets already located in image\n",
        "                                    break\n",
        "\n",
        "            # Append statistics (correct, conf, pcls, tcls)\n",
        "            stats.append((correct.cpu(), pred[:, 4].cpu(), pred[:, 5].cpu(), tcls))\n",
        "\n",
        "        # Plot images\n",
        "        if batch_i < 1:\n",
        "            f = 'test_batch%g_gt.jpg' % batch_i  # filename\n",
        "            plot_images(img, targets, paths, f, names)  # ground truth\n",
        "            f = 'test_batch%g_pred.jpg' % batch_i\n",
        "            plot_images(img, output_to_target(output, width, height), paths, f, names)  # predictions\n",
        "\n",
        "    # Compute statistics\n",
        "    stats = [np.concatenate(x, 0) for x in zip(*stats)]  # to numpy\n",
        "    if len(stats):\n",
        "        p, r, ap, f1, ap_class = ap_per_class(*stats)\n",
        "        p, r, ap50, ap = p[:, 0], r[:, 0], ap[:, 0], ap.mean(1)  # [P, R, AP@0.5, AP@0.5:0.95]\n",
        "        mp, mr, map50, map = p.mean(), r.mean(), ap50.mean(), ap.mean()\n",
        "        nt = np.bincount(stats[3].astype(np.int64), minlength=nc)  # number of targets per class\n",
        "    else:\n",
        "        nt = torch.zeros(1)\n",
        "\n",
        "    # Print results\n",
        "    pf = '%20s' + '%12.3g' * 6  # print format\n",
        "    print(pf % ('all', seen, nt.sum(), mp, mr, map50, map))\n",
        "\n",
        "    # Print results per class\n",
        "    if verbose and nc > 1 and len(stats):\n",
        "        for i, c in enumerate(ap_class):\n",
        "            print(pf % (names[c], seen, nt[c], p[i], r[i], ap50[i], ap[i]))\n",
        "\n",
        "    # Print speeds\n",
        "    t = tuple(x / seen * 1E3 for x in (t0, t1, t0 + t1)) + (imgsz, imgsz, batch_size)  # tuple\n",
        "    if not training:\n",
        "        print('Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g' % t)\n",
        "\n",
        "    # Save JSON\n",
        "    if save_json and map50 and len(jdict):\n",
        "        imgIds = [int(Path(x).stem.split('_')[-1]) for x in dataloader.dataset.img_files]\n",
        "        f = 'detections_val2017_%s_results.json' % \\\n",
        "            (weights.split(os.sep)[-1].replace('.pt', '') if weights else '')  # filename\n",
        "        print('\\nCOCO mAP with pycocotools... saving %s...' % f)\n",
        "        with open(f, 'w') as file:\n",
        "            json.dump(jdict, file)\n",
        "\n",
        "        try:\n",
        "            from pycocotools.coco import COCO\n",
        "            from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "            # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
        "            cocoGt = COCO(glob.glob('../coco/annotations/instances_val*.json')[0])  # initialize COCO ground truth api\n",
        "            cocoDt = cocoGt.loadRes(f)  # initialize COCO pred api\n",
        "\n",
        "            cocoEval = COCOeval(cocoGt, cocoDt, 'bbox')\n",
        "            cocoEval.params.imgIds = imgIds  # image IDs to evaluate\n",
        "            cocoEval.evaluate()\n",
        "            cocoEval.accumulate()\n",
        "            cocoEval.summarize()\n",
        "            map, map50 = cocoEval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
        "        except:\n",
        "            print('WARNING: pycocotools must be installed with numpy==1.17 to run correctly. '\n",
        "                  'See https://github.com/cocodataset/cocoapi/issues/356')\n",
        "\n",
        "    # Return results\n",
        "    model.float()  # for training\n",
        "    maps = np.zeros(nc) + map\n",
        "    for i, c in enumerate(ap_class):\n",
        "        maps[c] = ap[i]\n",
        "    return (mp, mr, map50, map, *(loss.cpu() / len(dataloader)).tolist()), maps, t\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(prog='test.py')\n",
        "    parser.add_argument('--weights', type=str, default='weights/yolov5s.pt', help='model.pt path')\n",
        "    parser.add_argument('--data', type=str, default='data/coco128.yaml', help='*.data path')\n",
        "    parser.add_argument('--batch-size', type=int, default=32, help='size of each image batch')\n",
        "    parser.add_argument('--img-size', type=int, default=640, help='inference size (pixels)')\n",
        "    parser.add_argument('--conf-thres', type=float, default=0.001, help='object confidence threshold')\n",
        "    parser.add_argument('--iou-thres', type=float, default=0.65, help='IOU threshold for NMS')\n",
        "    parser.add_argument('--save-json', action='store_true', help='save a cocoapi-compatible JSON results file')\n",
        "    parser.add_argument('--task', default='val', help=\"'val', 'test', 'study'\")\n",
        "    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
        "    parser.add_argument('--single-cls', action='store_true', help='treat as single-class dataset')\n",
        "    parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
        "    parser.add_argument('--merge', action='store_true', help='use Merge NMS')\n",
        "    parser.add_argument('--verbose', action='store_true', help='report mAP by class')\n",
        "    opt = parser.parse_args()\n",
        "    opt.save_json = opt.save_json or opt.data.endswith('coco.yaml')\n",
        "    opt.data = check_file(opt.data)  # check file\n",
        "    print(opt)\n",
        "\n",
        "    # task = 'val', 'test', 'study'\n",
        "    if opt.task in ['val', 'test']:  # (default) run normally\n",
        "        test(opt.data,\n",
        "             opt.weights,\n",
        "             opt.batch_size,\n",
        "             opt.img_size,\n",
        "             opt.conf_thres,\n",
        "             opt.iou_thres,\n",
        "             opt.save_json,\n",
        "             opt.single_cls,\n",
        "             opt.augment,\n",
        "             opt.verbose)\n",
        "\n",
        "    elif opt.task == 'study':  # run over a range of settings and save/plot\n",
        "        for weights in ['yolov5s.pt', 'yolov5m.pt', 'yolov5l.pt', 'yolov5x.pt', 'yolov3-spp.pt']:\n",
        "            f = 'study_%s_%s.txt' % (Path(opt.data).stem, Path(weights).stem)  # filename to save to\n",
        "            x = list(range(352, 832, 64))  # x axis\n",
        "            y = []  # y axis\n",
        "            for i in x:  # img-size\n",
        "                print('\\nRunning %s point %s...' % (f, i))\n",
        "                r, _, t = test(opt.data, weights, opt.batch_size, i, opt.conf_thres, opt.iou_thres, opt.save_json)\n",
        "                y.append(r + t)  # results and times\n",
        "            np.savetxt(f, y, fmt='%10.4g')  # save\n",
        "        os.system('zip -r study.zip study_*.txt')\n",
        "        # plot_study_txt(f, x)  # plot"
      ]
    }
  ]
}